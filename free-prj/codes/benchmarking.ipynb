{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import *\n",
    "import os, gzip, pickle\n",
    "import pandas as pd\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make Dataframe from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dataframe with clip dataset\n",
    "# Final output : DataFrame[@Sequence @RBP @Class]\n",
    "\n",
    "\n",
    "# Various type of RBPs in Train/Test Dataset\n",
    "clip_list = [\n",
    "    'Ago-EIF',\n",
    "    'Ago2-MNase',\n",
    "    'Ago2-1',\n",
    "    'Ago2-2',\n",
    "    'Ago2',\n",
    "    'eIF4III-1',\n",
    "    'eIF4III-2',\n",
    "    'ELAVL1-1',\n",
    "    'ELAVL1-MNase',\n",
    "    'ELAVL1A',\n",
    "    'ELAVL1-2',\n",
    "    'ESWR1',\n",
    "    'FUS',\n",
    "    'Mut_FUS',\n",
    "    'IGFBP1-3',\n",
    "    'hnRNPC-1',\n",
    "    'hnRNPC-2',\n",
    "    'hnRNPL-1',\n",
    "    'hnRNPL-2',\n",
    "    'hnRNPL-like',\n",
    "    'MOV10',\n",
    "    'Nsun2',\n",
    "    'PUM2',\n",
    "    'QKI',\n",
    "    'SRSF1',\n",
    "    'TAF15',\n",
    "    'TDP-43',\n",
    "    'TIA1',\n",
    "    'TIAL1',\n",
    "    'U2AF2',\n",
    "    'U2AF2-KD'\n",
    "]\n",
    "\n",
    "# read (FASTA) file path and return list of parsed object (sequences)\n",
    "# Input : FASTA file (path), Class file (path) --> per Protein\n",
    "# Output : list of (sequence, class) tuples\n",
    "def read_fa(fa_path, clss_path):\n",
    "    seqs = []\n",
    "    seq = ''    \n",
    "    with gzip.open(fa_path, 'r') as fa, gzip.open(clss_path, 'r') as cl:# files are compressed with bgzip\n",
    "        clss = cl.readlines()\n",
    "        clss = [int(x.decode('utf-8')) for x in clss[1:]] # class label\n",
    "\n",
    "        i = 0\n",
    "        for line in fa:\n",
    "            line = line.decode('utf-8') # bytes -> string\n",
    "            if line[0] == '>': # need to skip this header line with after extra jobs\n",
    "                if len(seqs) == 0 and seq == '': # just skip header of fisrst sequence in fa\n",
    "                    continue\n",
    "                else:\n",
    "                    seqs.append((seq, clss[i])) # add sequence to seqs\n",
    "                    i += 1\n",
    "                    seq = '' # reinitialize with empty string\n",
    "                    continue\n",
    "            else:\n",
    "                seq += line.rstrip() # concatenate sequence without '\\n' to seq\n",
    "        \n",
    "        seqs.append((seq, clss[i]))\n",
    "    \n",
    "    return seqs\n",
    "\n",
    "\n",
    "# Make DataFrame\n",
    "def mk_frame(data_rt_head, file_list, seq_tail, clss_tail, df_name):\n",
    "    seqs = {}\n",
    "    i = 0\n",
    "    \n",
    "    for file in file_list:\n",
    "        seq_path = data_rt_head + '/' + file + seq_tail\n",
    "        clss_path = data_rt_head + '/' + file + clss_tail\n",
    "        seqs[clip_list[i]] = read_fa(seq_path, clss_path)\n",
    "        i += 1\n",
    "    \n",
    "    # len(seqs) : number of RBPs\n",
    "    # len(seqs[clip_list[0]]) : number of seqs per RBP -> 1K(test) or 5K(train) or 10K(test) or 30K(train)\n",
    "    if len(seqs) != 31 or len(seqs[clip_list[0]]) not in [1000, 5000, 10000, 30000]:\n",
    "        print('len(seqs) :', len(seqs))\n",
    "        print('len(seqs[clip_list[0]])', len(seqs[clip_list[0]]))\n",
    "        raise IndexNotMatching\n",
    "\n",
    "    df_seqs = pd.DataFrame(\n",
    "        [(seq, rbp, clss) for (rbp, seq_clss_pair) in seqs.items() for (seq, clss) in seq_clss_pair],\n",
    "        #[(var, key) for (key, L) in seqs_test.items() for var in L],\n",
    "        columns=['Sequence', 'RBP', 'Class']\n",
    "    )\n",
    "\n",
    "    df_seqs['RBP'] = df_seqs['RBP'].astype('category')\n",
    "    df_seqs['Class'] = df_seqs['Class'].astype('category')\n",
    "\n",
    "    df_seqs.to_feather('./../dataset/objs/' + df_name + '.ftr') # save dataframe as object\n",
    "\n",
    "    return df_seqs\n",
    "\n",
    "\n",
    "def concat_frame(dfs, df_name):\n",
    "    if type(dfs) != 'list':\n",
    "        return dfs\n",
    "    \n",
    "    df_total = pd.concat(dfs)\n",
    "\n",
    "    df_total.to_feather('./../dataset/objs/' + df_name + '.ftr')\n",
    "\n",
    "    return df_total\n",
    "\n",
    "\n",
    "# Single Sample set in 5K dataset\n",
    "data_rt_5k = \"./../dataset/clip5000\"\n",
    "files_5k = natsorted(os.listdir(data_rt_5k))\n",
    "train_seq_tail_5k = \"/5000/training_sample_0/sequences.fa.gz\"\n",
    "train_clss_tail_5k = train_seq_tail_5k.replace('sequences.fa', 'matrix_Response.tab')\n",
    "test_seq_tail_5k = train_seq_tail_5k.replace('training', 'test')\n",
    "test_clss_tail_5k = train_clss_tail_5k.replace('training', 'test')\n",
    "\n",
    "# 3 Sample sets in 30K dataset\n",
    "data_rt_30k = \"./../dataset/clip\"\n",
    "files_30k = natsorted(os.listdir(data_rt_30k))\n",
    "train_seqs_tails_30k = [\"/30000/training_sample_\" + str(i) + \"/sequences.fa.gz\" for i in range(3)]\n",
    "train_clss_tails_30k = [seq_tail.replace('sequences.fa', 'matrix_Response.tab') for seq_tail in train_seqs_tails_30k]\n",
    "test_seqs_tails_30k = [seq_tail.replace('training', 'test') for seq_tail in train_seqs_tails_30k]\n",
    "test_clss_tails_30k = [seq_tail.replace('sequences.fa', 'matrix_Response.tab') for seq_tail in test_seqs_tails_30k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_5k = mk_frame(\n",
    "    data_rt_head=data_rt_5k,\n",
    "    file_list=files_5k,\n",
    "    seq_tail=train_seq_tail_5k,\n",
    "    clss_tail=train_clss_tail_5k,\n",
    "    df_name='train_5k'\n",
    ")\n",
    "\n",
    "df_test_5k = mk_frame(\n",
    "    data_rt_head=data_rt_5k,\n",
    "    file_list=files_5k,\n",
    "    seq_tail=test_seq_tail_5k,\n",
    "    clss_tail=test_clss_tail_5k,\n",
    "    df_name='test_5k'\n",
    ")\n",
    "\n",
    "'''\n",
    "df_train_lst = [\n",
    "    mk_frame(data_rt_30k, files_30k, train_30k_tail[i][0], train_30k_tail[i][1], 'train_30k_' + str(i)) \\\n",
    "        for train_30k_tail in zip(train_seqs_tails_30k, train_clss_tails_30k) for i in range(len(train_seqs_tails_30k))\n",
    "]\n",
    "\n",
    "df_test_lst = [\n",
    "    mk_frame(data_rt_30k, files_30k, test_30k_tail[i][0], test_30k_tail[i][1], 'test_30k_' + str(i)) \\\n",
    "        for test_30k_tail in zip(test_seqs_tails_30k, test_clss_tails_30k) for i in range(len(test_seqs_tails_30k))\n",
    "]\n",
    "\n",
    "df_train_30k = concat_frame(df_train_lst, 'train_30k')\n",
    "\n",
    "df_test_30k = concat_frame(df_test_lst, 'test_30k')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f81ca079b9101c07fe85c8b090c9e2cc9c56a877851e75c4fbd4dbec9ea9fed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
